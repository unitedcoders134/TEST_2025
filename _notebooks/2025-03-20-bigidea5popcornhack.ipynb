{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "---\n",
    "layout: post\n",
    "title:  Big Idea 5 Popcorn hack\n",
    "description:  Big Idea 5\n",
    "permalink: /bigidea5/\n",
    "courses: { csp: {week 1} } \n",
    "comments: true\n",
    "sticky_rank: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "source": [
    "## Popcorn Hack #1. \n",
    "\n",
    "\n",
    "One way that technological innovations can impact society in a positive way is by enhancing medical procedures - such as less of a margin of error for surgery procedures. For example, BayMax, the robot nurse. There are also things like self driving cars which help us.\n",
    "\n",
    "One way that it could be harmful is by promoting cyberbullying and fostering a community with negative impacts to people. There also could be privacy losses and data breaches. Too much dependance on technology can mak you lose your critical thinking skills and more. There also would be some economic displacements - with AI taking jobs. Drones can also \n",
    "\n",
    "Ai can also be very dangerous: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #2 \n",
    "\n",
    "The meaning of negative effects of technology is that technology does have a few impacts that can negatively effect our lives. One example of this being avoidd is a drone being programmed to not take unathorized photos of people and in restricted areas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #3\n",
    "\n",
    "It's important to understand the unintended consequences of technology, especially dopamine driven technology because iit's likely that it'll have a harmful effect on our lives, and often without any of us realizing it. This can lead to multiple things, for example social media addiction which can take lots of time off our lives and lead us to crave dopamine throughout our day - which impacts our ability to complete tasks and our focuses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Hack 1\n",
    "\n",
    "**AI Technology**: GPT-Based Language Models\n",
    "**Original Use**:\n",
    "GPT-based AI, like ChatGPT, was originally designed for natural language understanding and generation. It is primarily used for tasks like answering questions, summarizing text, generating content, and assisting with coding.\n",
    "\n",
    "**New Use Case**: AI-Powered Legal Advocate for Underprivileged Communities\n",
    "Instead of just being a general chatbot, GPT-based AI can be trained to assist individuals in legal self-representation. Many people cannot afford legal representation, so AI could provide free, easy-to-understand legal guidance, helping users:\n",
    "\n",
    "- Understand their rights in civil cases.\n",
    "- Draft legal documents like contracts or tenant complaints.\n",
    "- Navigate court procedures and deadlines.\n",
    "- Simulate legal conversations to prepare for hearings.\n",
    "- Impact Analysis\n",
    "**Benefits**:\n",
    "- Increased Access to Justice – AI could help millions of underprivileged individuals get legal - assistance they otherwise couldn't afford.\n",
    "- Efficiency & Cost Reduction – It would reduce the time and costs associated with legal consultations for simple cases, helping courts operate more smoothly.\n",
    "**Risks**:\n",
    "- Misinformation & Legal Liability – If AI provides incorrect or outdated legal advice, users might lose their case or face legal consequences.\n",
    "- Bias & Ethical Concerns – AI models trained on biased legal data could unintentionally reinforce systemic inequalities in the justice system.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Hack #2: Ethical AI Coding Challenge\n",
    "Problem: AI-generated misinformation (e.g., deepfakes and fake news).\n",
    "\n",
    "Risk: AI can create fake videos, images, and articles that spread misinformation, influencing public opinion, elections, and trust in real news sources. This can lead to social unrest, deception, and loss of credibility in media.\n",
    "\n",
    "Solution 1: Implement AI-powered fact-checking tools that analyze and verify the accuracy of AI-generated content before it spreads online.\n",
    "\n",
    "Solution 2: Require digital watermarks and metadata tracking for AI-generated media, making it easier to detect and flag fake content.\n",
    "\n",
    "Reflection: Ethical AI development is crucial to prevent harm and maintain trust in technology. Without responsible safeguards, AI can be misused to manipulate people and spread false information. By incorporating transparency and verification systems, we can ensure AI is used to inform rather than deceive.\n",
    "\n",
    "\n",
    "\n",
    "## Homework Hack #3  \n",
    "\n",
    "**AI Example**: Amazon's AI Recruiting Tool\n",
    "\n",
    "**What Happened**:\n",
    "Amazon developed an AI system in the 2010s to automate the process of reviewing job applicants’ resumes. The AI was trained using data from resumes submitted over a 10-year period, mostly by male applicants. As a result, the system began to favor male candidates and penalize resumes that included words like “women’s,” such as “women’s chess club captain.” It unintentionally learned to be biased against female applicants, reinforcing gender discrimination.\n",
    "\n",
    "**Response**:\n",
    "Once Amazon discovered the bias, the company disbanded the project in 2018 and did not deploy the AI recruiting tool for official hiring decisions. The incident also sparked broader discussions in the tech industry about fairness and bias in AI.\n",
    "\n",
    "**Prevention**:\n",
    "Developers could have avoided this problem by:\n",
    "\n",
    "- Auditing the training data for bias before using it.\n",
    "- Testing the AI’s outputs across different demographics (e.g., gender, race) during development.\n",
    "- Including diverse teams during AI development to catch blind spots.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
